{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18002aa6-39a1-4e71-8749-324e2f615f31",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Challenge 04-A - Retrieval Augmented Generation (RAG) for Structured Data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4ca1751",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, we will explore the practical application of RAG with a more manageable type of data i.e structured data such as relational data or text data stored in csv files. The main objective is to introduce a specific use case that demonstrates the utilization of Azure Cognitive Search to extract relevant documents and the power of ChatGPT to address relevant portions of the document, providing concise summaries based on user prompts. It aims to showcase how Azure OpenAI's ChatGPT capabilities can be adapted to suit your summarization needs, while also guiding you through the setup and evaluation of summarization results. This method can be customized to suit various summarization use cases and applied to diverse datasets.\n",
    "\n",
    "This notebook leverages **Semantic Kernel** as an orchestration framework to coordinate multiple AI services and manage the RAG workflow. Semantic Kernel provides:\n",
    "\n",
    "- **Service Management**: Centralized registration and access to Azure OpenAI services (chat completion and embeddings)\n",
    "- **Execution Orchestration**: Coordinated execution of embedding generation, similarity search, and response generation\n",
    "- **Configuration Management**: Unified handling of model parameters and execution settings\n",
    "- **Async Operations**: Efficient handling of concurrent AI service calls\n",
    "\n",
    "The kernel acts as the central hub that orchestrates the interaction between Azure Cognitive Search for document retrieval and Azure OpenAI for embeddings and completions.\n",
    "\n",
    "## Student Tasks\n",
    "Your goals for this challenge are to read through this notebook and complete the code where there is a TODO comment. Use Github Copilot to write the code! Ensure you run each code block, observe the results, and then be able to answer the questions posed in the student guide."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f2d0025-3952-481b-9615-cfe5ee198f66",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Use Case\n",
    "\n",
    "This use case consists of three sections:\n",
    "- Document Search - The process of extracting relevant documents based on the query from a corpus of documents.\n",
    "- Document Zone Search - The process of finding the relevant part of the document extracted from document search.\n",
    "- Downstream AI tasks such as Question Answering (aka Text summarization) - Text summarization is the process of creating summaries from large volumes of data while maintaining significant informational elements and content value.\n",
    "This use case can be useful in helping subject matter experts in finding relevant information from large document corpus.\n",
    "\n",
    "**Example:** In the drug discovery process, scientists in pharmaceutical industry read a corpus of documents to find specific information related to concepts, experiment results etc. This use case enables them to ask questions from the document corpus and the solution will come back with the succinct answer. Consequently, expediting the drug discovery process.\n",
    " \n",
    "Benefits of the solution:\n",
    "1. Shortens reading time\n",
    "2. Improves the effectiveness of searching for information\n",
    "3. Removes bias from human summarization techniques\n",
    "4. Increases bandwidth for humans to focus on more in-depth analysis \n",
    "\n",
    "\n",
    "The need for document summarization be applied to any subject matter (legal, financial, journalist, medical, academic, etc) that requires long document summarization. The subject matter that this notebook is focusing on is journalistic - we will walk through news articles.   \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85743c37-40f6-493f-9eaa-e9c4857ba8eb",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### CNN & Daily Mail Dataset\n",
    "For this walkthrough, we will be using the CNN/Daily Mail dataset. This is a common dataset used for text summarization and question answering tasks. Human generated abstractive summary bullets were generated from news stories on the CNN and Daily Mail websites.\n",
    "\n",
    "\n",
    "### Data Description\n",
    "The relevant schema for our work today consists of:\n",
    "\n",
    "- `id`: a string containing the heximal formatted SHA1 hash of the URL where the story was retrieved from\n",
    "- `article`: a string containing the body of the news article\n",
    "- `highlights`: a string containing the highlight of the article as written by the article author\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5b3fe1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/site-packages (from -r ../requirements.txt (line 1)) (78.1.1)\n",
      "Requirement already satisfied: azure-search-documents==11.4.0b3 in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 2)) (11.4.0b3)\n",
      "Requirement already satisfied: azure-ai-formrecognizer==3.2.1 in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 3)) (3.2.1)\n",
      "Requirement already satisfied: python-dotenv in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 4)) (1.2.1)\n",
      "Requirement already satisfied: num2words==0.5.12 in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 5)) (0.5.12)\n",
      "Requirement already satisfied: openai>=1.98.0 in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 6)) (2.21.0)\n",
      "Requirement already satisfied: pdfminer==20191125 in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 7)) (20191125)\n",
      "Requirement already satisfied: plotly==6.0.1 in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 8)) (6.0.1)\n",
      "Requirement already satisfied: tiktoken in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 9)) (0.12.0)\n",
      "Requirement already satisfied: scikit-learn in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 10)) (1.8.0)\n",
      "Requirement already satisfied: pandas in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 11)) (2.3.3)\n",
      "Requirement already satisfied: langchain in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 12)) (1.2.10)\n",
      "Requirement already satisfied: PyPDF3 in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 13)) (1.0.6)\n",
      "Requirement already satisfied: spacy in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 14)) (3.8.11)\n",
      "Requirement already satisfied: matplotlib in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 15)) (3.10.8)\n",
      "Requirement already satisfied: scipy in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 16)) (1.17.0)\n",
      "Requirement already satisfied: datasets in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 17)) (4.5.0)\n",
      "Requirement already satisfied: evaluate in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 18)) (0.4.6)\n",
      "Requirement already satisfied: azure-identity in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 20)) (1.25.2)\n",
      "Requirement already satisfied: azure-ai-evaluation in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 21)) (1.15.1)\n",
      "Requirement already satisfied: semantic-kernel in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 23)) (1.37.0)\n",
      "Requirement already satisfied: azure-ai-projects in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 24)) (2.0.0b3)\n",
      "Requirement already satisfied: pyrit in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 25)) (0.11.0)\n",
      "Requirement already satisfied: numpy in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 26)) (1.26.4)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.24.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-search-documents==11.4.0b3->-r ../requirements.txt (line 2)) (1.38.2)\n",
      "Requirement already satisfied: azure-common~=1.1 in /home/vscode/.local/lib/python3.11/site-packages (from azure-search-documents==11.4.0b3->-r ../requirements.txt (line 2)) (1.1.28)\n",
      "Requirement already satisfied: isodate>=0.6.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-search-documents==11.4.0b3->-r ../requirements.txt (line 2)) (0.7.2)\n",
      "Requirement already satisfied: msrest>=0.6.21 in /home/vscode/.local/lib/python3.11/site-packages (from azure-ai-formrecognizer==3.2.1->-r ../requirements.txt (line 3)) (0.7.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in /home/vscode/.local/lib/python3.11/site-packages (from azure-ai-formrecognizer==3.2.1->-r ../requirements.txt (line 3)) (4.15.0)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /home/vscode/.local/lib/python3.11/site-packages (from num2words==0.5.12->-r ../requirements.txt (line 5)) (0.6.2)\n",
      "Requirement already satisfied: pycryptodome in /home/vscode/.local/lib/python3.11/site-packages (from pdfminer==20191125->-r ../requirements.txt (line 7)) (3.23.0)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /home/vscode/.local/lib/python3.11/site-packages (from plotly==6.0.1->-r ../requirements.txt (line 8)) (2.16.0)\n",
      "Requirement already satisfied: packaging in /home/vscode/.local/lib/python3.11/site-packages (from plotly==6.0.1->-r ../requirements.txt (line 8)) (26.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/vscode/.local/lib/python3.11/site-packages (from openai>=1.98.0->-r ../requirements.txt (line 6)) (4.12.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/vscode/.local/lib/python3.11/site-packages (from openai>=1.98.0->-r ../requirements.txt (line 6)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/vscode/.local/lib/python3.11/site-packages (from openai>=1.98.0->-r ../requirements.txt (line 6)) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /home/vscode/.local/lib/python3.11/site-packages (from openai>=1.98.0->-r ../requirements.txt (line 6)) (0.13.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/vscode/.local/lib/python3.11/site-packages (from openai>=1.98.0->-r ../requirements.txt (line 6)) (2.11.10)\n",
      "Requirement already satisfied: sniffio in /home/vscode/.local/lib/python3.11/site-packages (from openai>=1.98.0->-r ../requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/vscode/.local/lib/python3.11/site-packages (from openai>=1.98.0->-r ../requirements.txt (line 6)) (4.67.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/vscode/.local/lib/python3.11/site-packages (from tiktoken->-r ../requirements.txt (line 9)) (2026.2.19)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/vscode/.local/lib/python3.11/site-packages (from tiktoken->-r ../requirements.txt (line 9)) (2.32.5)\n",
      "Requirement already satisfied: joblib>=1.3.0 in /home/vscode/.local/lib/python3.11/site-packages (from scikit-learn->-r ../requirements.txt (line 10)) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from scikit-learn->-r ../requirements.txt (line 10)) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/vscode/.local/lib/python3.11/site-packages (from pandas->-r ../requirements.txt (line 11)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/vscode/.local/lib/python3.11/site-packages (from pandas->-r ../requirements.txt (line 11)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/vscode/.local/lib/python3.11/site-packages (from pandas->-r ../requirements.txt (line 11)) (2025.3)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.10 in /home/vscode/.local/lib/python3.11/site-packages (from langchain->-r ../requirements.txt (line 12)) (1.2.14)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.8 in /home/vscode/.local/lib/python3.11/site-packages (from langchain->-r ../requirements.txt (line 12)) (1.0.9)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/vscode/.local/lib/python3.11/site-packages (from spacy->-r ../requirements.txt (line 14)) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from spacy->-r ../requirements.txt (line 14)) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/vscode/.local/lib/python3.11/site-packages (from spacy->-r ../requirements.txt (line 14)) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/vscode/.local/lib/python3.11/site-packages (from spacy->-r ../requirements.txt (line 14)) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/vscode/.local/lib/python3.11/site-packages (from spacy->-r ../requirements.txt (line 14)) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /home/vscode/.local/lib/python3.11/site-packages (from spacy->-r ../requirements.txt (line 14)) (8.3.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/vscode/.local/lib/python3.11/site-packages (from spacy->-r ../requirements.txt (line 14)) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/vscode/.local/lib/python3.11/site-packages (from spacy->-r ../requirements.txt (line 14)) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/vscode/.local/lib/python3.11/site-packages (from spacy->-r ../requirements.txt (line 14)) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /home/vscode/.local/lib/python3.11/site-packages (from spacy->-r ../requirements.txt (line 14)) (0.4.3)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /home/vscode/.local/lib/python3.11/site-packages (from spacy->-r ../requirements.txt (line 14)) (0.24.0)\n",
      "Requirement already satisfied: jinja2 in /home/vscode/.local/lib/python3.11/site-packages (from spacy->-r ../requirements.txt (line 14)) (3.1.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/vscode/.local/lib/python3.11/site-packages (from matplotlib->-r ../requirements.txt (line 15)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/vscode/.local/lib/python3.11/site-packages (from matplotlib->-r ../requirements.txt (line 15)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/vscode/.local/lib/python3.11/site-packages (from matplotlib->-r ../requirements.txt (line 15)) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/vscode/.local/lib/python3.11/site-packages (from matplotlib->-r ../requirements.txt (line 15)) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /home/vscode/.local/lib/python3.11/site-packages (from matplotlib->-r ../requirements.txt (line 15)) (12.1.1)\n",
      "Requirement already satisfied: pyparsing>=3 in /home/vscode/.local/lib/python3.11/site-packages (from matplotlib->-r ../requirements.txt (line 15)) (3.3.2)\n",
      "Requirement already satisfied: filelock in /home/vscode/.local/lib/python3.11/site-packages (from datasets->-r ../requirements.txt (line 17)) (3.24.3)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from datasets->-r ../requirements.txt (line 17)) (23.0.1)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /home/vscode/.local/lib/python3.11/site-packages (from datasets->-r ../requirements.txt (line 17)) (0.4.0)\n",
      "Requirement already satisfied: xxhash in /home/vscode/.local/lib/python3.11/site-packages (from datasets->-r ../requirements.txt (line 17)) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /home/vscode/.local/lib/python3.11/site-packages (from datasets->-r ../requirements.txt (line 17)) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /home/vscode/.local/lib/python3.11/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r ../requirements.txt (line 17)) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /home/vscode/.local/lib/python3.11/site-packages (from datasets->-r ../requirements.txt (line 17)) (1.4.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/vscode/.local/lib/python3.11/site-packages (from datasets->-r ../requirements.txt (line 17)) (6.0.3)\n",
      "Requirement already satisfied: pyjwt>=2.8.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-ai-evaluation[redteam]->-r ../requirements.txt (line 19)) (2.11.0)\n",
      "Requirement already satisfied: nltk>=3.9.1 in /home/vscode/.local/lib/python3.11/site-packages (from azure-ai-evaluation[redteam]->-r ../requirements.txt (line 19)) (3.9.2)\n",
      "Requirement already satisfied: azure-storage-blob>=12.19.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-ai-evaluation[redteam]->-r ../requirements.txt (line 19)) (12.28.0)\n",
      "Requirement already satisfied: ruamel.yaml<1.0.0,>=0.17.10 in /home/vscode/.local/lib/python3.11/site-packages (from azure-ai-evaluation[redteam]->-r ../requirements.txt (line 19)) (0.19.1)\n",
      "Requirement already satisfied: aiohttp>=3.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-ai-evaluation[redteam]->-r ../requirements.txt (line 19)) (3.13.3)\n",
      "Requirement already satisfied: aiofiles<25,>=24 in /home/vscode/.local/lib/python3.11/site-packages (from pyrit->-r ../requirements.txt (line 25)) (24.1.0)\n",
      "Requirement already satisfied: appdirs>=1.4.0 in /home/vscode/.local/lib/python3.11/site-packages (from pyrit->-r ../requirements.txt (line 25)) (1.4.4)\n",
      "Requirement already satisfied: art>=6.5.0 in /home/vscode/.local/lib/python3.11/site-packages (from pyrit->-r ../requirements.txt (line 25)) (6.5)\n",
      "Requirement already satisfied: azure-ai-contentsafety>=1.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from pyrit->-r ../requirements.txt (line 25)) (1.0.0)\n",
      "Requirement already satisfied: base2048>=0.1.3 in /home/vscode/.local/lib/python3.11/site-packages (from pyrit->-r ../requirements.txt (line 25)) (0.1.3)\n",
      "Requirement already satisfied: colorama>=0.4.6 in /home/vscode/.local/lib/python3.11/site-packages (from pyrit->-r ../requirements.txt (line 25)) (0.4.6)\n",
      "Requirement already satisfied: confusables>=1.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from pyrit->-r ../requirements.txt (line 25)) (1.2.0)\n",
      "Requirement already satisfied: confusable-homoglyphs>=3.3.1 in /home/vscode/.local/lib/python3.11/site-packages (from pyrit->-r ../requirements.txt (line 25)) (3.3.1)\n",
      "Requirement already satisfied: ecoji>=0.1.1 in /home/vscode/.local/lib/python3.11/site-packages (from pyrit->-r ../requirements.txt (line 25)) (0.1.1)\n",
      "Requirement already satisfied: fastapi>=0.115.0 in /home/vscode/.local/lib/python3.11/site-packages (from pyrit->-r ../requirements.txt (line 25)) (0.129.0)\n",
      "Requirement already satisfied: openpyxl>=3.1.5 in /home/vscode/.local/lib/python3.11/site-packages (from pyrit->-r ../requirements.txt (line 25)) (3.1.5)\n",
      "Requirement already satisfied: pyodbc>=5.1.0 in /home/vscode/.local/lib/python3.11/site-packages (from pyrit->-r ../requirements.txt (line 25)) (5.3.0)\n",
      "Requirement already satisfied: pypdf>=5.1.0 in /home/vscode/.local/lib/python3.11/site-packages (from pyrit->-r ../requirements.txt (line 25)) (6.7.1)\n",
      "Requirement already satisfied: reportlab>=4.4.4 in /home/vscode/.local/lib/python3.11/site-packages (from pyrit->-r ../requirements.txt (line 25)) (4.4.10)\n",
      "Requirement already satisfied: segno>=1.6.6 in /home/vscode/.local/lib/python3.11/site-packages (from pyrit->-r ../requirements.txt (line 25)) (1.6.6)\n",
      "Requirement already satisfied: SQLAlchemy>=2.0.41 in /home/vscode/.local/lib/python3.11/site-packages (from pyrit->-r ../requirements.txt (line 25)) (2.0.46)\n",
      "Requirement already satisfied: termcolor>=2.4.0 in /home/vscode/.local/lib/python3.11/site-packages (from pyrit->-r ../requirements.txt (line 25)) (3.3.0)\n",
      "Requirement already satisfied: tenacity>=9.1.2 in /home/vscode/.local/lib/python3.11/site-packages (from pyrit->-r ../requirements.txt (line 25)) (9.1.4)\n",
      "Requirement already satisfied: tinytag>=2.1.1 in /home/vscode/.local/lib/python3.11/site-packages (from pyrit->-r ../requirements.txt (line 25)) (2.2.0)\n",
      "Requirement already satisfied: transformers>=4.52.4 in /home/vscode/.local/lib/python3.11/site-packages (from pyrit->-r ../requirements.txt (line 25)) (5.2.0)\n",
      "Requirement already satisfied: treelib>=1.7.1 in /home/vscode/.local/lib/python3.11/site-packages (from pyrit->-r ../requirements.txt (line 25)) (1.8.0)\n",
      "Requirement already satisfied: uvicorn>=0.32.0 in /home/vscode/.local/lib/python3.11/site-packages (from uvicorn[standard]>=0.32.0->pyrit->-r ../requirements.txt (line 25)) (0.41.0)\n",
      "Requirement already satisfied: websockets>=14.0 in /home/vscode/.local/lib/python3.11/site-packages (from pyrit->-r ../requirements.txt (line 25)) (15.0.1)\n",
      "Requirement already satisfied: cryptography>=2.5 in /home/vscode/.local/lib/python3.11/site-packages (from azure-identity->-r ../requirements.txt (line 20)) (46.0.5)\n",
      "Requirement already satisfied: msal>=1.31.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-identity->-r ../requirements.txt (line 20)) (1.34.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-identity->-r ../requirements.txt (line 20)) (1.3.1)\n",
      "Requirement already satisfied: azure-ai-agents>=1.2.0b3 in /home/vscode/.local/lib/python3.11/site-packages (from semantic-kernel->-r ../requirements.txt (line 23)) (1.2.0b6)\n",
      "Requirement already satisfied: cloudevents~=1.0 in /home/vscode/.local/lib/python3.11/site-packages (from semantic-kernel->-r ../requirements.txt (line 23)) (1.12.0)\n",
      "Requirement already satisfied: pydantic-settings~=2.0 in /home/vscode/.local/lib/python3.11/site-packages (from semantic-kernel->-r ../requirements.txt (line 23)) (2.13.1)\n",
      "Requirement already satisfied: defusedxml~=0.7 in /home/vscode/.local/lib/python3.11/site-packages (from semantic-kernel->-r ../requirements.txt (line 23)) (0.7.1)\n",
      "Requirement already satisfied: openapi_core<0.20,>=0.18 in /home/vscode/.local/lib/python3.11/site-packages (from semantic-kernel->-r ../requirements.txt (line 23)) (0.19.5)\n",
      "Requirement already satisfied: aiortc>=1.9.0 in /home/vscode/.local/lib/python3.11/site-packages (from semantic-kernel->-r ../requirements.txt (line 23)) (1.14.0)\n",
      "Requirement already satisfied: opentelemetry-api~=1.24 in /home/vscode/.local/lib/python3.11/site-packages (from semantic-kernel->-r ../requirements.txt (line 23)) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-sdk~=1.24 in /home/vscode/.local/lib/python3.11/site-packages (from semantic-kernel->-r ../requirements.txt (line 23)) (1.39.1)\n",
      "Requirement already satisfied: prance<25.4.9,>=23.6.21 in /home/vscode/.local/lib/python3.11/site-packages (from semantic-kernel->-r ../requirements.txt (line 23)) (25.4.8.0)\n",
      "Requirement already satisfied: pybars4~=0.9 in /home/vscode/.local/lib/python3.11/site-packages (from semantic-kernel->-r ../requirements.txt (line 23)) (0.9.13)\n",
      "Requirement already satisfied: nest-asyncio~=1.6 in /home/vscode/.local/lib/python3.11/site-packages (from semantic-kernel->-r ../requirements.txt (line 23)) (1.6.0)\n",
      "Requirement already satisfied: protobuf in /home/vscode/.local/lib/python3.11/site-packages (from semantic-kernel->-r ../requirements.txt (line 23)) (6.33.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp>=3.0->azure-ai-evaluation[redteam]->-r ../requirements.txt (line 19)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp>=3.0->azure-ai-evaluation[redteam]->-r ../requirements.txt (line 19)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp>=3.0->azure-ai-evaluation[redteam]->-r ../requirements.txt (line 19)) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp>=3.0->azure-ai-evaluation[redteam]->-r ../requirements.txt (line 19)) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp>=3.0->azure-ai-evaluation[redteam]->-r ../requirements.txt (line 19)) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp>=3.0->azure-ai-evaluation[redteam]->-r ../requirements.txt (line 19)) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp>=3.0->azure-ai-evaluation[redteam]->-r ../requirements.txt (line 19)) (1.22.0)\n",
      "Requirement already satisfied: aioice<1.0.0,>=0.10.1 in /home/vscode/.local/lib/python3.11/site-packages (from aiortc>=1.9.0->semantic-kernel->-r ../requirements.txt (line 23)) (0.10.2)\n",
      "Requirement already satisfied: av<17.0.0,>=14.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiortc>=1.9.0->semantic-kernel->-r ../requirements.txt (line 23)) (16.1.0)\n",
      "Requirement already satisfied: google-crc32c>=1.1 in /home/vscode/.local/lib/python3.11/site-packages (from aiortc>=1.9.0->semantic-kernel->-r ../requirements.txt (line 23)) (1.8.0)\n",
      "Requirement already satisfied: pyee>=13.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiortc>=1.9.0->semantic-kernel->-r ../requirements.txt (line 23)) (13.0.1)\n",
      "Requirement already satisfied: pylibsrtp>=0.10.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiortc>=1.9.0->semantic-kernel->-r ../requirements.txt (line 23)) (1.0.0)\n",
      "Requirement already satisfied: pyopenssl>=25.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiortc>=1.9.0->semantic-kernel->-r ../requirements.txt (line 23)) (25.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/vscode/.local/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai>=1.98.0->-r ../requirements.txt (line 6)) (3.11)\n",
      "Requirement already satisfied: deprecation<3.0,>=2.0 in /home/vscode/.local/lib/python3.11/site-packages (from cloudevents~=1.0->semantic-kernel->-r ../requirements.txt (line 23)) (2.1.0)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from cryptography>=2.5->azure-identity->-r ../requirements.txt (line 20)) (2.0.0)\n",
      "Requirement already satisfied: starlette<1.0.0,>=0.40.0 in /home/vscode/.local/lib/python3.11/site-packages (from fastapi>=0.115.0->pyrit->-r ../requirements.txt (line 25)) (0.52.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/vscode/.local/lib/python3.11/site-packages (from fastapi>=0.115.0->pyrit->-r ../requirements.txt (line 25)) (0.4.2)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /home/vscode/.local/lib/python3.11/site-packages (from fastapi>=0.115.0->pyrit->-r ../requirements.txt (line 25)) (0.0.4)\n",
      "Requirement already satisfied: certifi in /home/vscode/.local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=1.98.0->-r ../requirements.txt (line 6)) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /home/vscode/.local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=1.98.0->-r ../requirements.txt (line 6)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/vscode/.local/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.98.0->-r ../requirements.txt (line 6)) (0.16.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /home/vscode/.local/lib/python3.11/site-packages (from httpx[http2]>=0.27.2->pyrit->-r ../requirements.txt (line 25)) (4.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets->-r ../requirements.txt (line 17)) (1.2.0)\n",
      "Requirement already satisfied: shellingham in /home/vscode/.local/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets->-r ../requirements.txt (line 17)) (1.5.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/vscode/.local/lib/python3.11/site-packages (from jinja2->spacy->-r ../requirements.txt (line 14)) (3.0.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /home/vscode/.local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.10->langchain->-r ../requirements.txt (line 12)) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /home/vscode/.local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.10->langchain->-r ../requirements.txt (line 12)) (0.7.5)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /home/vscode/.local/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.10->langchain->-r ../requirements.txt (line 12)) (0.14.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /home/vscode/.local/lib/python3.11/site-packages (from langgraph<1.1.0,>=1.0.8->langchain->-r ../requirements.txt (line 12)) (4.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.8 in /home/vscode/.local/lib/python3.11/site-packages (from langgraph<1.1.0,>=1.0.8->langchain->-r ../requirements.txt (line 12)) (1.0.8)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /home/vscode/.local/lib/python3.11/site-packages (from langgraph<1.1.0,>=1.0.8->langchain->-r ../requirements.txt (line 12)) (0.3.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in /home/vscode/.local/lib/python3.11/site-packages (from msrest>=0.6.21->azure-ai-formrecognizer==3.2.1->-r ../requirements.txt (line 3)) (2.0.0)\n",
      "Requirement already satisfied: click in /home/vscode/.local/lib/python3.11/site-packages (from nltk>=3.9.1->azure-ai-evaluation[redteam]->-r ../requirements.txt (line 19)) (8.3.1)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in /home/vscode/.local/lib/python3.11/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel->-r ../requirements.txt (line 23)) (4.26.0)\n",
      "Requirement already satisfied: jsonschema-path<0.4.0,>=0.3.1 in /home/vscode/.local/lib/python3.11/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel->-r ../requirements.txt (line 23)) (0.3.4)\n",
      "Requirement already satisfied: more-itertools in /home/vscode/.local/lib/python3.11/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel->-r ../requirements.txt (line 23)) (10.8.0)\n",
      "Requirement already satisfied: openapi-schema-validator<0.7.0,>=0.6.0 in /home/vscode/.local/lib/python3.11/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel->-r ../requirements.txt (line 23)) (0.6.3)\n",
      "Requirement already satisfied: openapi-spec-validator<0.8.0,>=0.7.1 in /home/vscode/.local/lib/python3.11/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel->-r ../requirements.txt (line 23)) (0.7.2)\n",
      "Requirement already satisfied: parse in /home/vscode/.local/lib/python3.11/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel->-r ../requirements.txt (line 23)) (1.21.1)\n",
      "Requirement already satisfied: werkzeug<3.1.2 in /home/vscode/.local/lib/python3.11/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel->-r ../requirements.txt (line 23)) (3.1.1)\n",
      "Requirement already satisfied: et-xmlfile in /home/vscode/.local/lib/python3.11/site-packages (from openpyxl>=3.1.5->pyrit->-r ../requirements.txt (line 25)) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /home/vscode/.local/lib/python3.11/site-packages (from opentelemetry-api~=1.24->semantic-kernel->-r ../requirements.txt (line 23)) (8.7.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /home/vscode/.local/lib/python3.11/site-packages (from opentelemetry-sdk~=1.24->semantic-kernel->-r ../requirements.txt (line 23)) (0.60b1)\n",
      "Requirement already satisfied: chardet>=5.2 in /home/vscode/.local/lib/python3.11/site-packages (from prance<25.4.9,>=23.6.21->semantic-kernel->-r ../requirements.txt (line 23)) (5.2.0)\n",
      "Requirement already satisfied: PyMeta3>=0.5.1 in /home/vscode/.local/lib/python3.11/site-packages (from pybars4~=0.9->semantic-kernel->-r ../requirements.txt (line 23)) (0.5.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/vscode/.local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai>=1.98.0->-r ../requirements.txt (line 6)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/vscode/.local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai>=1.98.0->-r ../requirements.txt (line 6)) (2.33.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/vscode/.local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->-r ../requirements.txt (line 11)) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer in /home/vscode/.local/lib/python3.11/site-packages (from reportlab>=4.4.4->pyrit->-r ../requirements.txt (line 25)) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vscode/.local/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->-r ../requirements.txt (line 9)) (2.6.3)\n",
      "Requirement already satisfied: greenlet>=1 in /home/vscode/.local/lib/python3.11/site-packages (from SQLAlchemy>=2.0.41->pyrit->-r ../requirements.txt (line 25)) (3.3.1)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /home/vscode/.local/lib/python3.11/site-packages (from thinc<8.4.0,>=8.3.4->spacy->-r ../requirements.txt (line 14)) (1.3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/vscode/.local/lib/python3.11/site-packages (from thinc<8.4.0,>=8.3.4->spacy->-r ../requirements.txt (line 14)) (0.1.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/vscode/.local/lib/python3.11/site-packages (from transformers>=4.52.4->pyrit->-r ../requirements.txt (line 25)) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/vscode/.local/lib/python3.11/site-packages (from transformers>=4.52.4->pyrit->-r ../requirements.txt (line 25)) (0.7.0)\n",
      "Requirement already satisfied: typer>=0.24.0 in /home/vscode/.local/lib/python3.11/site-packages (from typer-slim<1.0.0,>=0.3.0->spacy->-r ../requirements.txt (line 14)) (0.24.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /home/vscode/.local/lib/python3.11/site-packages (from uvicorn[standard]>=0.32.0->pyrit->-r ../requirements.txt (line 25)) (0.7.1)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /home/vscode/.local/lib/python3.11/site-packages (from uvicorn[standard]>=0.32.0->pyrit->-r ../requirements.txt (line 25)) (0.22.1)\n",
      "Requirement already satisfied: watchfiles>=0.20 in /home/vscode/.local/lib/python3.11/site-packages (from uvicorn[standard]>=0.32.0->pyrit->-r ../requirements.txt (line 25)) (1.1.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /home/vscode/.local/lib/python3.11/site-packages (from weasel<0.5.0,>=0.4.2->spacy->-r ../requirements.txt (line 14)) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /home/vscode/.local/lib/python3.11/site-packages (from weasel<0.5.0,>=0.4.2->spacy->-r ../requirements.txt (line 14)) (7.5.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from aioice<1.0.0,>=0.10.1->aiortc>=1.9.0->semantic-kernel->-r ../requirements.txt (line 23)) (2.8.0)\n",
      "Requirement already satisfied: ifaddr>=0.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from aioice<1.0.0,>=0.10.1->aiortc>=1.9.0->semantic-kernel->-r ../requirements.txt (line 23)) (0.2.0)\n",
      "Requirement already satisfied: pycparser in /home/vscode/.local/lib/python3.11/site-packages (from cffi>=2.0.0->cryptography>=2.5->azure-identity->-r ../requirements.txt (line 20)) (3.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /home/vscode/.local/lib/python3.11/site-packages (from h2<5,>=3->httpx[http2]>=0.27.2->pyrit->-r ../requirements.txt (line 25)) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /home/vscode/.local/lib/python3.11/site-packages (from h2<5,>=3->httpx[http2]>=0.27.2->pyrit->-r ../requirements.txt (line 25)) (4.1.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/vscode/.local/lib/python3.11/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api~=1.24->semantic-kernel->-r ../requirements.txt (line 23)) (3.23.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/vscode/.local/lib/python3.11/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.10->langchain->-r ../requirements.txt (line 12)) (3.0.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/vscode/.local/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel->-r ../requirements.txt (line 23)) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/vscode/.local/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel->-r ../requirements.txt (line 23)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in /home/vscode/.local/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel->-r ../requirements.txt (line 23)) (0.30.0)\n",
      "Requirement already satisfied: pathable<0.5.0,>=0.4.1 in /home/vscode/.local/lib/python3.11/site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel->-r ../requirements.txt (line 23)) (0.4.4)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in /home/vscode/.local/lib/python3.11/site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.8->langchain->-r ../requirements.txt (line 12)) (1.12.2)\n",
      "Requirement already satisfied: orjson>=3.11.5 in /home/vscode/.local/lib/python3.11/site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.8->langchain->-r ../requirements.txt (line 12)) (3.11.7)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain->-r ../requirements.txt (line 12)) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/vscode/.local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain->-r ../requirements.txt (line 12)) (0.25.0)\n",
      "Requirement already satisfied: rfc3339-validator in /home/vscode/.local/lib/python3.11/site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic-kernel->-r ../requirements.txt (line 23)) (0.1.4)\n",
      "Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in /home/vscode/.local/lib/python3.11/site-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic-kernel->-r ../requirements.txt (line 23)) (1.12.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-ai-formrecognizer==3.2.1->-r ../requirements.txt (line 3)) (3.3.1)\n",
      "Requirement already satisfied: wrapt in /home/vscode/.local/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy->-r ../requirements.txt (line 14)) (2.1.1)\n",
      "Requirement already satisfied: rich>=12.3.0 in /home/vscode/.local/lib/python3.11/site-packages (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy->-r ../requirements.txt (line 14)) (14.3.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy->-r ../requirements.txt (line 14)) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/vscode/.local/lib/python3.11/site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy->-r ../requirements.txt (line 14)) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/vscode/.local/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy->-r ../requirements.txt (line 14)) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69bd738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Azure Cognitive Search, Semantic Kernel, and other python modules\n",
    "\n",
    "import os, json, requests, sys, re\n",
    "import asyncio\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "# Azure Cognitive Search imports\n",
    "from azure.search.documents.indexes import SearchIndexClient \n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    "    SemanticConfiguration,\n",
    "    PrioritizedFields,\n",
    "    SemanticField,\n",
    "    SemanticSettings\n",
    ")\n",
    "\n",
    "# Semantic Kernel imports for core services\n",
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureTextEmbedding\n",
    "from semantic_kernel.contents import ChatHistory\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatPromptExecutionSettings\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "token_provider = get_bearer_token_provider(\n",
    "    DefaultAzureCredential(),\n",
    "    \"https://cognitiveservices.azure.com/.default\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf4cc4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Kernel services initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables and initialize Semantic Kernel services\n",
    "chat_model = os.environ['CHAT_MODEL_NAME']\n",
    "embedding_model = os.environ['EMBEDDING_MODEL_NAME']\n",
    "\n",
    "# Initialize Semantic Kernel\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "# Add Azure OpenAI Chat Completion service with Entra ID authentication\n",
    "chat_service = AzureChatCompletion(\n",
    "    deployment_name=chat_model,\n",
    "    endpoint=os.environ['OPENAI_API_BASE'],\n",
    "    ad_token_provider=token_provider\n",
    ")\n",
    "kernel.add_service(chat_service)\n",
    "\n",
    "# Add Azure OpenAI Text Embedding service with Entra ID authentication\n",
    "embedding_service = AzureTextEmbedding(\n",
    "    deployment_name=embedding_model,\n",
    "    endpoint=os.environ['OPENAI_API_BASE'],\n",
    "    ad_token_provider=token_provider\n",
    ")\n",
    "kernel.add_service(embedding_service)\n",
    "\n",
    "print(\"Semantic Kernel services initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20c44e3",
   "metadata": {},
   "source": [
    "**NOTE:** The path in the code cell below is referring to the `cnn_dailymail.csv` file in the `/data/structured/` folder. You may need to update this path if you are running this notebook from a different location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9019bf3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92c514c913c0bdfe25341af9fd72b29db544099b</td>\n",
       "      <td>Ever noticed how plane seats appear to be gett...</td>\n",
       "      <td>Experts question if  packed out planes are put...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003841c7dc0e7c5b1a248f9cd536d727f27a45a</td>\n",
       "      <td>A drunk teenage boy had to be rescued by secur...</td>\n",
       "      <td>Drunk teenage boy climbed into lion enclosure ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91b7d2311527f5c2b63a65ca98d21d9c92485149</td>\n",
       "      <td>Dougie Freedman is on the verge of agreeing a ...</td>\n",
       "      <td>Nottingham Forest are close to extending Dougi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>caabf9cbdf96eb1410295a673e953d304391bfbb</td>\n",
       "      <td>Liverpool target Neto is also wanted by PSG an...</td>\n",
       "      <td>Fiorentina goalkeeper Neto has been linked wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3da746a7d9afcaa659088c8366ef6347fe6b53ea</td>\n",
       "      <td>Bruce Jenner will break his silence in a two-h...</td>\n",
       "      <td>Tell-all interview with the reality TV star, 6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  \\\n",
       "0  92c514c913c0bdfe25341af9fd72b29db544099b   \n",
       "1  2003841c7dc0e7c5b1a248f9cd536d727f27a45a   \n",
       "2  91b7d2311527f5c2b63a65ca98d21d9c92485149   \n",
       "3  caabf9cbdf96eb1410295a673e953d304391bfbb   \n",
       "4  3da746a7d9afcaa659088c8366ef6347fe6b53ea   \n",
       "\n",
       "                                             article  \\\n",
       "0  Ever noticed how plane seats appear to be gett...   \n",
       "1  A drunk teenage boy had to be rescued by secur...   \n",
       "2  Dougie Freedman is on the verge of agreeing a ...   \n",
       "3  Liverpool target Neto is also wanted by PSG an...   \n",
       "4  Bruce Jenner will break his silence in a two-h...   \n",
       "\n",
       "                                          highlights  \n",
       "0  Experts question if  packed out planes are put...  \n",
       "1  Drunk teenage boy climbed into lion enclosure ...  \n",
       "2  Nottingham Forest are close to extending Dougi...  \n",
       "3  Fiorentina goalkeeper Neto has been linked wit...  \n",
       "4  Tell-all interview with the reality TV star, 6...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the CNN dailymail dataset in pandas dataframe\n",
    "df = pd.read_csv('../data/structured/cnn_dailymail_data.csv') #path to CNN daily mail dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11eff67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.search.documents.indexes._search_index_client.SearchIndexClient at 0x7d985056b890>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Cognitive Search Index client with Entra ID authentication\n",
    "from azure.identity import AzureCliCredential\n",
    "\n",
    "service_endpoint = os.getenv(\"AZURE_AI_SEARCH_ENDPOINT\")   \n",
    "\n",
    "# Use AzureCliCredential for local development (more reliable than DefaultAzureCredential)\n",
    "credential = AzureCliCredential()\n",
    "\n",
    "index_name = \"news-index\"\n",
    "\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=service_endpoint, credential=credential)\n",
    "index_client"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b30a67db",
   "metadata": {},
   "source": [
    "### Define Index Fields and Create a Semantic Configuration\n",
    "\n",
    "A *semantic configuration* specifies how fields are used in semantic ranking. It gives the underlying models hints about which index fields are most important for semantic ranking, captions, highlights, and answers.\n",
    "\n",
    "You can add or update a semantic configuration at any time without rebuilding your index. When you issue a query, you'll add the semantic configuration (one per query) that specifies which semantic configuration to use for the query.\n",
    "\n",
    "Review the properties you'll need to specify. A semantic configuration has a name and at least one each of the following properties:\n",
    "\n",
    "* Title field - A title field should be a concise description of the document, ideally a string that is under 25 words. This field could be the title of the document, name of the product, or item in your search index. If you don't have a title in your search index, leave this field blank.\n",
    "* Content fields - Content fields should contain text in natural language form. Common examples of content are the body of a document, the description of a product, or other free-form text.\n",
    "* Keyword fields - Keyword fields should be a list of keywords, such as the tags on a document, or a descriptive term, such as the category of an item.\n",
    "\n",
    "You can only specify one title field but you can specify as many content and keyword fields as you like. For content and keyword fields, list the fields in priority order because lower priority fields may get truncated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a325dd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " news-index created\n"
     ]
    }
   ],
   "source": [
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "    SearchableField(name=\"highlights\", type=SearchFieldDataType.String,\n",
    "                searchable=True, retrievable=True),\n",
    "    SearchableField(name=\"article\", type=SearchFieldDataType.String,\n",
    "                filterable=True, searchable=True, retrievable=True),\n",
    "]\n",
    "\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"my-semantic-config\",\n",
    "    prioritized_fields=PrioritizedFields(\n",
    "        #title_field=SemanticField(field_name=\"\"), # title field is not present in the dataset. We can use OpenAI to generate title\n",
    "        #prioritized_keywords_fields=[SemanticField(field_name=\"\")], # keywords are not present in the dataset. We can use OpenAI to generate keywords\n",
    "        prioritized_content_fields=[SemanticField(field_name=\"article\"), SemanticField(field_name=\"highlights\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the semantic settings with the configuration\n",
    "semantic_settings = SemanticSettings(configurations=[semantic_config])\n",
    "\n",
    "# Create the search index with the semantic settings\n",
    "index = SearchIndex(name=index_name, fields=fields, semantic_settings=semantic_settings)\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f' {result.name} created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4869992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '92c514c913c0bdfe25341af9fd72b29db544099b',\n",
       " 'article': \"Ever noticed how plane seats appear to be getting smaller and smaller? With increasing numbers of people taking to the skies, some experts are questioning if having such packed out planes is putting passengers at risk. They say that the shrinking space on aeroplanes is not only uncomfortable - it's putting our health and safety in danger. More than squabbling over the arm rest, shrinking space on planes putting our health and safety in danger? This week, a U.S consumer advisory group set up by the Department of Transportation said at a public hearing that while the government is happy to set standards for animals flying on planes, it doesn't stipulate a minimum amount of space for humans. 'In a world where animals have more rights to space and food than humans,' said Charlie Leocha, consumer representative on the committee.\\xa0'It is time that the DOT and FAA take a stand for humane treatment of passengers.' But could crowding on planes lead to more serious issues than fighting for space in the overhead lockers, crashing elbows and seat back kicking? Tests conducted by the FAA use planes with a 31 inch pitch, a standard which on some airlines has decreased . Many economy seats on United Airlines have 30 inches of room, while some airlines offer as little as 28 inches . Cynthia Corbertt, a human factors researcher with the Federal Aviation Administration, that it conducts tests on how quickly passengers can leave a plane. But these tests are conducted using planes with 31 inches between each row of seats, a standard which on some airlines has decreased, reported the Detroit News. The distance between two seats from one point on a seat to the same point on the seat behind it is known as the pitch. While most airlines stick to a pitch of 31 inches or above, some fall below this. While United Airlines has 30 inches of space, Gulf Air economy seats have between 29 and 32 inches, Air Asia offers 29 inches and Spirit Airlines offers just 28 inches. British Airways has a seat pitch of 31 inches, while easyJet has 29 inches, Thomson's short haul seat pitch is 28 inches, and Virgin Atlantic's is 30-31.\",\n",
       " 'highlights': 'Experts question if  packed out planes are putting passengers at risk .\\nU.S consumer advisory group says minimum space must be stipulated .\\nSafety tests conducted on planes with more leg room than airlines offer .'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = df.to_dict('records')\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76b3fe21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11490"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9022d69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded and Indexed 11490 documents\n"
     ]
    }
   ],
   "source": [
    "search_client = SearchClient(endpoint=service_endpoint, index_name=index_name, credential=credential)\n",
    "result = search_client.upload_documents(documents)  \n",
    "print(f\"Uploaded and Indexed {len(result)} documents\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc09a779-e3cd-485f-ae3a-297491d993b0",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Section 1: Leveraging Cognitive Search to extract relevant article based on the query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32689db7-4337-42d9-b8f9-4cbd9d98a850",
   "metadata": {
    "gather": {
     "logged": 1675138710195
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Semantic Kernel helper functions\n",
    "# These functions demonstrate the orchestration pattern where the kernel\n",
    "# manages service discovery and execution, providing a clean abstraction\n",
    "# over the underlying Azure OpenAI services\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureTextEmbedding, AzureChatCompletion\n",
    "\n",
    "#Student Task: Complete the get_embedding function\n",
    "async def get_embedding(kernel, text):\n",
    "   # 1. Get the embedding service by its type (AzureTextEmbedding)\n",
    "    embedding_service = kernel.get_service(type=AzureTextEmbedding)\n",
    "    \n",
    "    # 2. Use the generate_embeddings function to create the vector\n",
    "    # This expects a list of strings, so we wrap 'text' in [ ]\n",
    "    embeddings = await embedding_service.generate_embeddings([text])\n",
    "    return embeddings\n",
    "\n",
    "async def get_completion(kernel, prompt, temperature):\n",
    "    # Get the chat service by type\n",
    "    chat_service = kernel.get_service(type=AzureChatCompletion)\n",
    "    \n",
    "    # Create execution settings\n",
    "    settings = AzureChatPromptExecutionSettings(\n",
    "        temperature=temperature,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    \n",
    "    # Create a proper ChatHistory object with the user prompt\n",
    "    chat_history = ChatHistory()\n",
    "    chat_history.add_user_message(prompt)\n",
    "    \n",
    "    # Generate completion\n",
    "    response = await chat_service.get_chat_message_content(\n",
    "        chat_history=chat_history,\n",
    "        settings=settings\n",
    "    )\n",
    "    \n",
    "    return response.content\n",
    "\n",
    "def search_similar_chunks(query_embedding, chunks_df, top_k=3):\n",
    "    similarities = []\n",
    "    query_embedding = np.array(query_embedding).reshape(1, -1)\n",
    "    \n",
    "    for idx, embedding in enumerate(chunks_df['embedding']):\n",
    "        embedding_array = np.array(embedding).reshape(1, -1)\n",
    "        similarity = cosine_similarity(query_embedding, embedding_array)[0][0]\n",
    "        similarities.append((similarity, idx))\n",
    "    \n",
    "    similarities.sort(reverse=True)\n",
    "    results = []\n",
    "    for similarity, idx in similarities[:top_k]:\n",
    "        results.append({\n",
    "            'text': chunks_df.iloc[idx]['text'],\n",
    "            'score': similarity\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c9681f2-2448-4e6d-8174-5fb5ff61d5db",
   "metadata": {
    "gather": {
     "logged": 1675139624461
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved document for query: 'Laurene Jobs Hillary Clinton'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Apple founder Steve Jobs\\' widow Laurene has told of her admiration for Democratic White House front-runner Hillary Clinton. Ms Jobs, 51, called former First Lady Hillary a \\'revolutionary\\' woman, and added that it\\'s not just because she\\'s a woman - but \\'the type of woman she is\\'. Speaking to Time 100, Ms Jobs said: \\'Hillary Clinton is not familiar. She is revolutionary. Not radical, but revolutionary: The distinction is crucial. She is one of Americas greatest modern creations. Laurene Jobs, pictured, widow of Apple\\'s Steve, has strongly backed Hillary Clinton for president . Laurene Jobs said that Hillary Clinton, right, has \\'judgment and wisdom\\' based on her public service . \\'Her decades in our public life must not blind us to the fact that she represents new realities and possibilities. Indeed, those same decades have conferred upon her what newness usually lacks: judgment, and even wisdom. \\'It matters, of course, that Hillary is a woman. But what matters more is what kind of woman she is.\\' Mrs Clinton announced her intention to seek the Democratic nomination on Sunday - and set upon the campaign trail with a trip to meet \\'ordinary\\' voters in Iowa. But she was blasted for her \\'staged\\' visit on Tuesday morning to a coffee shop in LeClaire, Iowa. Austin Bird, one of the men pictured sitting at the table with Mrs Clinton, claimed the whole event was orchestrated \\'from beginning to end\\'. STAGED: Clinton sat to talk with three young Iowans at a coffee shop on Tuesday  all of whom were driven to the event by her Iowa campaign\\'s political director . NOT SO ORDINARY: Austin Bird is a Democratic Party insider who chauffeured Vice President Joe Biden around Davenport, Iowa in October during a pre-election campaign trip . Bird told Daily Mail Online that campaign staffer Troy Price called and asked him and two other young people to meet him Tuesday morning at a restaurant in Davenport, a nearby city. Price then drove them to the coffee house to meet Clinton after vetting them for about a half-hour. The three got the lion\\'s share of Mrs. Clinton\\'s time and participated in what breathless news reports described as a \\'roundtable\\' the first of many in her brief Iowa campaign swing. Bird himself is a frequent participant in Iowa Democratic Party events. He interned with President Obama\\'s 2012 presidential re-election campaign, and was tapped to chauffeur Vice President Joe Biden in October 2014 when he visited Davenport. \\'What happened is, we were just asked to be there by Troy,\\' Bird said Wednesday in a phone interview. \\'We were asked to come to a meeting with Troy, the three of us, at the Village Inn.\\' The other two, he confirmed, were University of Iowa College Democrats president Carter Bell and Planned Parenthood of the Heartland employee Sara Sedlacek. \\'It was supposed to be a strategy meeting,\\' Bird recalled, \\'to get our thoughts about issues. But then all of a sudden he says, \"Hey, we have Secretary Clinton coming in, would you like to go meet her?\"\\' \\'And then we got in a car  Troy\\'s car  and we went up to the coffee house, and we sat at a table and then Hillary just came up and talked with us.\\' Bird said \\'we all were called.\\' \\'I mean, Troy asked us all to do  to go to a meeting with him. And we didn\\'t really know what it was about. I mean, he did. He knew.\\' It\\'s unclear how many Iowans featured in photographs with Clinton that rocketed around the country on Tuesday were planted. \\'The mayor of LeClaire was there, and his wife was there,\\' Bird said, recalling the scene at the coffee shop. Price was executive director of the Iowa Democratic Party until a month ago. Clinton\\'s team tapped him last week to be its political director in Iowa. He did not respond to a request for comment. Bird is a government and community relations coordinator at Genesis Health System in Davenport, Iowa, according to his LinkedIn profile. A coworker at Genesis said Wednesday that Bird is \\'basically a lobbyist in training. That\\'s what he wants to do.\\' Bird disagreed, saying his role was \\'more public relations.\\' He\\'s also an outspoken progressive whose Facebook wall shows he ordered a \\'Hillary For President\\' bumper sticker\\xa022 months ago. \\'Is it 2016 yet?\\' he wrote in May 2013. Clinton\\'s nascent campaign has carefully coordinated her image as a spontaneous, handshaking populist in her first days as a candidate, posing with Pennsylvanians at a gas station and venturing into an Ohio Chipotle restaurant for lunch. When no one recognized the former first lady  she was wearing sunglasses  the campaign leaked information to The New York Times so its reporters could get security-camera footage to prove she had tried to mingle with voters. Scripting supposedly off-the-cuff appearances is common in presidential politics but could hurt Clinton especially hard since her gonzo road-trip journey to America\\'s broad midwest is designed to counter her image as cold, calculating and politically venomous. And planting party insiders in place of typical Iowans won\\'t go over well in the Hawkeye State, where pressing the flesh and collecting caucus votes is a quadrennial full-contact sport. ASTROTURF: Setting up faux events for news cameras is nothing new in politics, but Iowans take presidential contests seriously and could punish Clinton for the deception . THE FIXER: Bird said Troy Prince (left, pictured with VP Joe Biden), who was executive director of the Iowa Democratic Party until he left last month to help Clinton\\'s statewide political effort, recruited him and others to attend the \\'spontaneous\\' coffee meeting . Clinton\\'s campaign has already taken heat for depicting at least three people in her campaign launch video as \\'everyday\\' Americans who were actually partisans with political connections. One was even a former campaign manager for Wendy Davis, the Texas Democrat who mounted a failed bid for Texas governor last year. In LeClaire on Tuesday,\\xa0Bloomberg and other outlets referred to Bird as a \\'student\\' at St. Ambrose University, not as a hospital government-affairs staffer with Democratic party street-cred. He does study at St. Ambrose  part-time. But Bird\\'s ties to the party are deep enough that his Facebook wall includes a photo of him standing in front of Joe Biden\\'s limousine in Davenport. \\'I was driving the Vice President when he was in town in October,\\' Bird noted in a Facebook comment. Biden was not there on official government business, but for a campaign stop in support of Democrat Bruce Braley. \\'The Vice President will attend a grassroots event for Braley for Iowa with Representative David Loebsack,\\' according to White House press guidance for his October 27, 2014 schedule.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for document about Laurene Jobs and Hillary Clinton\n",
    "search_query = \"Laurene Jobs Hillary Clinton\"\n",
    "results = search_client.search(search_text=search_query, top=1)\n",
    "\n",
    "document = list(results)[0]['article']\n",
    "print(f\"Retrieved document for query: '{search_query}'\")\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02375dcd-514e-4203-951e-729b3de07570",
   "metadata": {
    "gather": {
     "logged": 1675139635796
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6675"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#length of article extracted from Azure Cognitive search\n",
    "len(document) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b4b060-1dca-468c-a1f5-ac1b9e5d4878",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Section 2: Document Zone Search\n",
    "### Document Zone: Semantic Kernel Orchestrated Embeddings\n",
    "Now that we narrowed on a single document from our knowledge base using Azure Cognitive Search, we can dive deeper into the single document to refine our initial query to a more specific section or \"zone\" of the article.\n",
    "\n",
    "To do this, we will utilize Semantic Kernel's orchestrated Azure OpenAI Embeddings service.\n",
    "\n",
    "### **Embeddings Overview**\n",
    "An embedding is a special format of data representation that can be easily utilized by machine learning models and algorithms. The embedding is an information dense representation of the semantic meaning of a piece of text. Each embedding is a vector of floating-point numbers, such that the distance between two embeddings in the vector space is correlated with semantic similarity between two inputs in the original format. For example, if two texts are similar, then their vector representations should also be similar.\n",
    "\n",
    "Different Azure OpenAI embedding models are specifically created to be good at a particular task. Similarity embeddings are good at capturing semantic similarity between two or more pieces of text. Text search embeddings are useful for evaluating the relevance of long documents to a brief query. Code search embeddings are useful for embedding code snippets and embedding natural language search queries.\n",
    "\n",
    "Embeddings make it easier to do machine learning on large inputs representing words by capturing the semantic similarities in a vector space. Therefore, we can use embeddings to see if two text chunks are semantically related or similar, and inherently provide a score to assess similarity.\n",
    "\n",
    "### **Cosine Similarity**\n",
    "A previously used approach to match similar documents was based on counting maximum number of common words between documents. This is flawed since as the document size increases, the overlap of common words increases even if the topics differ. Therefore cosine similarity is a better approach.\n",
    "\n",
    "Mathematically, cosine similarity measures the cosine of the angle between two vectors projected in a multi-dimensional space. This is beneficial because if two documents are far apart by Euclidean distance because of size, they could still have a smaller angle between them and therefore higher cosine similarity.\n",
    "\n",
    "The Azure OpenAI embeddings rely on cosine similarity to compute similarity between documents and a query."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c178e3be",
   "metadata": {},
   "source": [
    "### **Chunking**\n",
    "\n",
    "Let's start with chunking. Why is chunking important when working with LLMs?\n",
    "\n",
    "Chunking helps overcome the challenges associated with processing long sequences and ensures optimal performance when working with LLMs.\n",
    "\n",
    "**Mitigating Token Limitations:** LLMs have a maximum token limit for each input sequence. If a document or input exceeds this limit, it needs to be divided into chunks that fit within the token constraints. Chunking allows the LLM to handle long documents or inputs by splitting them into multiple chunks that fall within the token limit. This ensures that the model can effectively process the entire content while adhering to the token constraints.\n",
    "\n",
    "**Memory and Computational Efficiency:** LLMs are computationally expensive and require substantial memory resources to process long sequences of text. Chunking involves breaking down long documents or input into smaller, manageable chunks, allowing the LLM to process them efficiently within its memory limitations. By dividing the input into smaller parts, chunking helps avoid memory errors or performance degradation that may occur when processing lengthy sequences.\n",
    "\n",
    "**Contextual Coherence:** Chunking helps maintain contextual coherence in the generated outputs. Instead of treating the entire input as a single sequence, breaking it into smaller chunks allows the model to capture local context more effectively. This improves the model's understanding of the relationships and dependencies within the text, leading to more coherent and meaningful generated responses.\n",
    "\n",
    "**Improved Parallelism:** Chunking enables parallel processing, which is essential for optimizing the performance of LLMs. By dividing the input into chunks, multiple chunks can be processed simultaneously, taking advantage of parallel computing capabilities. This leads to faster inference times and enhances overall efficiency when working with LLMs.\n",
    "\n",
    "We will be leveraging a basic splitter for this notebook. However, it's important to note that there are more advanced splitters available, which may better suit your specific use case. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea256fa6",
   "metadata": {},
   "source": [
    "### Orchestrated Multi-Step Processing\n",
    "\n",
    "The following section demonstrates how Semantic Kernel orchestrates a multi-step RAG process:\n",
    "1. **Document Chunking**: Breaking down retrieved documents into manageable pieces\n",
    "2. **Embedding Generation**: Using the orchestrated embedding service to create vector representations\n",
    "3. **Similarity Search**: Coordinating the search across embedded chunks\n",
    "4. **Response Generation**: Using the orchestrated chat service to generate final answers\n",
    "\n",
    "### Orchestration Benefits\n",
    "The Semantic Kernel orchestration pattern demonstrated in the helper functions above provides:\n",
    "- **Service Discovery**: Automatic lookup of registered services by type\n",
    "- **Lifecycle Management**: Proper initialization and cleanup of AI services  \n",
    "- **Configuration Consistency**: Centralized management of model parameters\n",
    "- **Error Handling**: Unified exception handling across all AI operations\n",
    "- **Async Coordination**: Efficient orchestration of concurrent AI service calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b043fbb4",
   "metadata": {
    "gather": {
     "logged": 1675138711079
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 11 chunks from document\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"Apple founder Steve Jobs' widow Laurene has told of her admiration for Democratic White House front-runner Hillary Clinton. Ms Jobs, 51, called former First Lady Hillary a 'revolutionary' woman, and added that it's not just because she's a woman - but 'the type of woman she is'. Speaking to Time 100, Ms Jobs said: 'Hillary Clinton is not familiar. She is revolutionary. Not radical, but revolutionary: The distinction is crucial\",\n",
       " \"She is one of Americas greatest modern creations. Laurene Jobs, pictured, widow of Apple's Steve, has strongly backed Hillary Clinton for president . Laurene Jobs said that Hillary Clinton, right, has 'judgment and wisdom' based on her public service . 'Her decades in our public life must not blind us to the fact that she represents new realities and possibilities. Indeed, those same decades have conferred upon her what newness usually lacks: judgment, and even wisdom\",\n",
       " \"'It matters, of course, that Hillary is a woman. But what matters more is what kind of woman she is.' Mrs Clinton announced her intention to seek the Democratic nomination on Sunday - and set upon the campaign trail with a trip to meet 'ordinary' voters in Iowa. But she was blasted for her 'staged' visit on Tuesday morning to a coffee shop in LeClaire, Iowa. Austin Bird, one of the men pictured sitting at the table with Mrs Clinton, claimed the whole event was orchestrated 'from beginning to end'. STAGED: Clinton sat to talk with three young Iowans at a coffee shop on Tuesday  all of whom were driven to the event by her Iowa campaign's political director \",\n",
       " \"NOT SO ORDINARY: Austin Bird is a Democratic Party insider who chauffeured Vice President Joe Biden around Davenport, Iowa in October during a pre-election campaign trip . Bird told Daily Mail Online that campaign staffer Troy Price called and asked him and two other young people to meet him Tuesday morning at a restaurant in Davenport, a nearby city. Price then drove them to the coffee house to meet Clinton after vetting them for about a half-hour. The three got the lion's share of Mrs. Clinton's time and participated in what breathless news reports described as a 'roundtable' the first of many in her brief Iowa campaign swing\",\n",
       " \"Bird himself is a frequent participant in Iowa Democratic Party events. He interned with President Obama's 2012 presidential re-election campaign, and was tapped to chauffeur Vice President Joe Biden in October 2014 when he visited Davenport. 'What happened is, we were just asked to be there by Troy,' Bird said Wednesday in a phone interview. 'We were asked to come to a meeting with Troy, the three of us, at the Village Inn.' The other two, he confirmed, were University of Iowa College Democrats president Carter Bell and Planned Parenthood of the Heartland employee Sara Sedlacek. 'It was supposed to be a strategy meeting,' Bird recalled, 'to get our thoughts about issues\",\n",
       " 'But then all of a sudden he says, \"Hey, we have Secretary Clinton coming in, would you like to go meet her?\"\\' \\'And then we got in a car  Troy\\'s car  and we went up to the coffee house, and we sat at a table and then Hillary just came up and talked with us.\\' Bird said \\'we all were called.\\' \\'I mean, Troy asked us all to do  to go to a meeting with him. And we didn\\'t really know what it was about. I mean, he did. He knew.\\' It\\'s unclear how many Iowans featured in photographs with Clinton that rocketed around the country on Tuesday were planted. \\'The mayor of LeClaire was there, and his wife was there,\\' Bird said, recalling the scene at the coffee shop',\n",
       " \"Price was executive director of the Iowa Democratic Party until a month ago. Clinton's team tapped him last week to be its political director in Iowa. He did not respond to a request for comment. Bird is a government and community relations coordinator at Genesis Health System in Davenport, Iowa, according to his LinkedIn profile. A coworker at Genesis said Wednesday that Bird is 'basically a lobbyist in training\",\n",
       " \"That's what he wants to do.' Bird disagreed, saying his role was 'more public relations.' He's also an outspoken progressive whose Facebook wall shows he ordered a 'Hillary For President' bumper sticker 22 months ago. 'Is it 2016 yet?' he wrote in May 2013. Clinton's nascent campaign has carefully coordinated her image as a spontaneous, handshaking populist in her first days as a candidate, posing with Pennsylvanians at a gas station and venturing into an Ohio Chipotle restaurant for lunch. When no one recognized the former first lady  she was wearing sunglasses  the campaign leaked information to The New York Times so its reporters could get security-camera footage to prove she had tried to mingle with voters. Scripting supposedly off-the-cuff appearances is common in presidential politics but could hurt Clinton especially hard since her gonzo road-trip journey to America's broad midwest is designed to counter her image as cold, calculating and politically venomous\",\n",
       " \"And planting party insiders in place of typical Iowans won't go over well in the Hawkeye State, where pressing the flesh and collecting caucus votes is a quadrennial full-contact sport. ASTROTURF: Setting up faux events for news cameras is nothing new in politics, but Iowans take presidential contests seriously and could punish Clinton for the deception . THE FIXER: Bird said Troy Prince (left, pictured with VP Joe Biden), who was executive director of the Iowa Democratic Party until he left last month to help Clinton's statewide political effort, recruited him and others to attend the 'spontaneous' coffee meeting . Clinton's campaign has already taken heat for depicting at least three people in her campaign launch video as 'everyday' Americans who were actually partisans with political connections. One was even a former campaign manager for Wendy Davis, the Texas Democrat who mounted a failed bid for Texas governor last year\",\n",
       " \"In LeClaire on Tuesday, Bloomberg and other outlets referred to Bird as a 'student' at St. Ambrose University, not as a hospital government-affairs staffer with Democratic party street-cred. He does study at St. Ambrose  part-time. But Bird's ties to the party are deep enough that his Facebook wall includes a photo of him standing in front of Joe Biden's limousine in Davenport\",\n",
       " \"'I was driving the Vice President when he was in town in October,' Bird noted in a Facebook comment. Biden was not there on official government business, but for a campaign stop in support of Democrat Bruce Braley. 'The Vice President will attend a grassroots event for Braley for Iowa with Representative David Loebsack,' according to White House press guidance for his October 27, 2014 schedule.\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text processing functions\n",
    "import re\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = text.replace(\"..\", \".\").replace(\". .\", \".\").replace(\"\\n\", \"\")\n",
    "    return text\n",
    "\n",
    "def split_into_chunks(text, sentences_per_chunk=5):\n",
    "    sentences = text.split(\". \")\n",
    "    chunks = []\n",
    "    for i in range(0, len(sentences), sentences_per_chunk):\n",
    "        chunk = \". \".join(sentences[i:i+sentences_per_chunk])\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "# Create document chunks\n",
    "if document:\n",
    "    # 1. Normalize the text (remove extra spaces, fix periods, strip newlines)\n",
    "    normalized_doc = normalize_text(document)\n",
    "    \n",
    "    # 2. Split the normalized text into chunks (defaulting to 5 sentences each)\n",
    "    document_chunks = split_into_chunks(normalized_doc)\n",
    "    print(f\"Created {len(document_chunks)} chunks from document\")\n",
    "else:\n",
    "    document_chunks = [\"Sample text chunk for testing\"]\n",
    "    print(\"Using sample chunks - no document found\")\n",
    "\n",
    "document_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56354758-427f-4af9-94b9-96a25946e9a5",
   "metadata": {
    "gather": {
     "logged": 1675138711316
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings for 11 chunks\n",
      "\n",
      "Query: What did Laurene Jobs say about Hillary Clinton?\n",
      "\n",
      "Result 1 (Score: 0.913):\n",
      "She is one of Americas greatest modern creations. Laurene Jobs, pictured, widow of Apple's Steve, has strongly backed Hillary Clinton for president . Laurene Jobs said that Hillary Clinton, right, ha...\n",
      "\n",
      "Result 2 (Score: 0.904):\n",
      "Apple founder Steve Jobs' widow Laurene has told of her admiration for Democratic White House front-runner Hillary Clinton. Ms Jobs, 51, called former First Lady Hillary a 'revolutionary' woman, and a...\n",
      "\n",
      "Result 3 (Score: 0.829):\n",
      "'It matters, of course, that Hillary is a woman. But what matters more is what kind of woman she is.' Mrs Clinton announced her intention to seek the Democratic nomination on Sunday - and set upon the...\n"
     ]
    }
   ],
   "source": [
    "# Create embeddings for document chunks\n",
    "embeddings = []\n",
    "for chunk in document_chunks:\n",
    "    #TODO: Generate embedding using get_embedding function and append to embeddings\n",
    "    # 1. Await the asynchronous get_embedding function\n",
    "    embedding = await get_embedding(kernel, chunk)\n",
    "    \n",
    "    # 2. Append the generated vector to our list\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "# Create DataFrame with text and embeddings\n",
    "import pandas as pd\n",
    "chunks_df = pd.DataFrame({\n",
    "    'text': document_chunks,\n",
    "    'embedding': embeddings\n",
    "})\n",
    "\n",
    "print(f\"Generated embeddings for {len(chunks_df)} chunks\")\n",
    "\n",
    "# Demo search\n",
    "user_query = \"What did Laurene Jobs say about Hillary Clinton?\"\n",
    "query_embedding = await get_embedding(kernel, user_query)\n",
    "search_results = search_similar_chunks(query_embedding, chunks_df, top_k=3)\n",
    "\n",
    "print(f\"\\nQuery: {user_query}\")\n",
    "for i, result in enumerate(search_results, 1):\n",
    "    print(f\"\\nResult {i} (Score: {result['score']:.3f}):\")\n",
    "    print(result['text'][:200] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39b3c83f-deca-493b-aa41-12b89f24feff",
   "metadata": {
    "gather": {
     "logged": 1675138711716
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Response:\n",
      "Laurene Jobs expressed strong support for Hillary Clinton, describing her as having \"judgment and wisdom\" based on her decades of public service. She admired Clinton as a \"revolutionary\" woman, emphasizing that it's not just because she's a woman, but because of \"the type of woman she is.\" Laurene Jobs highlighted that Clinton represents new realities and possibilities, and that her experience has endowed her with judgment and wisdom.\n"
     ]
    }
   ],
   "source": [
    "# Generate RAG response\n",
    "context = \"\\n\\n\".join([result['text'] for result in search_results])\n",
    "\n",
    "prompt = f\"\"\"Based on the following context, answer the question: {user_query}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "response = await get_completion(kernel, prompt, temperature=0)\n",
    "print(\"RAG Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de635ba5-7cf1-4d4f-8598-73619fc9c7ef",
   "metadata": {
    "gather": {
     "logged": 1675138711984
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunks</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple founder Steve Jobs' widow Laurene has to...</td>\n",
       "      <td>[[-0.02433471940457821, -0.008342213928699493,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She is one of Americas greatest modern creati...</td>\n",
       "      <td>[[-0.013851461932063103, -0.002175944857299328...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'It matters, of course, that Hillary is a woma...</td>\n",
       "      <td>[[-0.024904364719986916, -0.012944233603775501...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NOT SO ORDINARY: Austin Bird is a Democratic P...</td>\n",
       "      <td>[[-0.026654334738850594, -0.023114407435059547...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bird himself is a frequent participant in Iowa...</td>\n",
       "      <td>[[-0.0446157343685627, -0.04319649562239647, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              chunks  \\\n",
       "0  Apple founder Steve Jobs' widow Laurene has to...   \n",
       "1  She is one of Americas greatest modern creati...   \n",
       "2  'It matters, of course, that Hillary is a woma...   \n",
       "3  NOT SO ORDINARY: Austin Bird is a Democratic P...   \n",
       "4  Bird himself is a frequent participant in Iowa...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [[-0.02433471940457821, -0.008342213928699493,...  \n",
       "1  [[-0.013851461932063103, -0.002175944857299328...  \n",
       "2  [[-0.024904364719986916, -0.012944233603775501...  \n",
       "3  [[-0.026654334738850594, -0.023114407435059547...  \n",
       "4  [[-0.0446157343685627, -0.04319649562239647, 0...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative embedding DataFrame for compatibility\n",
    "embed_df = pd.DataFrame({\n",
    "    'chunks': document_chunks,\n",
    "    'embeddings': embeddings\n",
    "})\n",
    "\n",
    "embed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cc7adb8-93dd-4dfd-995a-8df893a98d99",
   "metadata": {
    "gather": {
     "logged": 1675138712417
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunks</th>\n",
       "      <th>similarities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That's what he wants to do.' Bird disagreed, s...</td>\n",
       "      <td>0.848092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And planting party insiders in place of typica...</td>\n",
       "      <td>0.844956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              chunks  similarities\n",
       "0  That's what he wants to do.' Bird disagreed, s...      0.848092\n",
       "1  And planting party insiders in place of typica...      0.844956"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Document search function\n",
    "def search_docs(df, user_query, top_n=3):\n",
    "    query_embedding = asyncio.get_event_loop().run_until_complete(get_embedding(kernel, user_query))\n",
    "    query_embedding = np.array(query_embedding).reshape(1, -1)\n",
    "    \n",
    "    similarities = []\n",
    "    for idx, embedding in enumerate(df['embeddings']):\n",
    "        embedding_array = np.array(embedding).reshape(1, -1)\n",
    "        similarity = cosine_similarity(query_embedding, embedding_array)[0][0]\n",
    "        similarities.append((similarity, idx))\n",
    "    \n",
    "    similarities.sort(reverse=True)\n",
    "    \n",
    "    results = []\n",
    "    for similarity, idx in similarities[:top_n]:\n",
    "        results.append({\n",
    "            'chunks': df.iloc[idx]['chunks'],\n",
    "            'similarities': similarity\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Search for specific content\n",
    "query = \"trouble so far in clinton campaign\"\n",
    "results = search_docs(embed_df, query, top_n=2)\n",
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eabac33e-5a98-49f0-8fd6-2750bcf79bb1",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Section 3: Text Summarization\n",
    "\n",
    "This section will cover the end-to-end flow of using the GPT-3 and ChatGPT models for summarization tasks. \n",
    "The model used by the Azure OpenAI service is a generative completion call which uses natural language instructions to identify the task being asked and skill required  aka Prompt Engineering. Using this approach, the first part of the prompt includes natural language instructions and/or examples of the specific task desired. The model then completes the task by predicting the most probable next text. This technique is known as \"in-context\" learning. \n",
    "\n",
    "There are three main approaches for in-context learning: Zero-shot, Few-shot and Fine tuning. These approaches vary based on the amount of task-specific data that is given to the model: \n",
    "\n",
    "**Zero-shot**: In this case, no examples are provided to the model and only the task request is provided. \n",
    "\n",
    "**Few-shot**: In this case, a user includes several examples in the call prompt that demonstrate the expected answer format and content. \n",
    "\n",
    "**Fine-Tuning**: Fine Tuning lets you tailor models to your personal datasets. This customization step will let you get more out of the service by providing: \n",
    "-\tWith lots of data (at least 500 and above) traditional optimization techniques are used with Back Propagation to re-adjust the weights of the model  this enables higher quality results than mere zero-shot or few-shot. \n",
    "-\tA customized model improves the few-shot learning approach by training the model weights on your specific prompts and structure. This lets you achieve better results on a wider number of tasks without needing to provide examples in the prompt. The result is less text sent and fewer tokens \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c8e47a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected chunks for summarization:\n",
      "1. That's what he wants to do.' Bird disagreed, saying his role was 'more public relations.' He's also an outspoken progressive whose Facebook wall shows he ordered a 'Hillary For President' bumper sticker 22 months ago. 'Is it 2016 yet?' he wrote in May 2013. Clinton's nascent campaign has carefully coordinated her image as a spontaneous, handshaking populist in her first days as a candidate, posing with Pennsylvanians at a gas station and venturing into an Ohio Chipotle restaurant for lunch. When no one recognized the former first lady  she was wearing sunglasses  the campaign leaked information to The New York Times so its reporters could get security-camera footage to prove she had tried to mingle with voters. Scripting supposedly off-the-cuff appearances is common in presidential politics but could hurt Clinton especially hard since her gonzo road-trip journey to America's broad midwest is designed to counter her image as cold, calculating and politically venomous\n",
      "2. And planting party insiders in place of typical Iowans won't go over well in the Hawkeye State, where pressing the flesh and collecting caucus votes is a quadrennial full-contact sport. ASTROTURF: Setting up faux events for news cameras is nothing new in politics, but Iowans take presidential contests seriously and could punish Clinton for the deception . THE FIXER: Bird said Troy Prince (left, pictured with VP Joe Biden), who was executive director of the Iowa Democratic Party until he left last month to help Clinton's statewide political effort, recruited him and others to attend the 'spontaneous' coffee meeting . Clinton's campaign has already taken heat for depicting at least three people in her campaign launch video as 'everyday' Americans who were actually partisans with political connections. One was even a former campaign manager for Wendy Davis, the Texas Democrat who mounted a failed bid for Texas governor last year\n",
      "Summary (Temperature=0.5):\n",
      "The Clinton campaign has been carefully orchestrating her public image as a relatable and spontaneous candidate in the early days of her presidential run. This includes staged appearances, such as posing with locals at a gas station and visiting a Chipotle in Ohio, with efforts to leak these moments to the media to enhance her populist image. However, this strategy has faced criticism, particularly in Iowa, where authenticity is valued in presidential contests. The campaign has been accused of planting party insiders in place of regular Iowans at events and has faced backlash for featuring politically connected individuals as \"everyday\" Americans in her campaign launch video. These tactics, common in politics, could backfire for Clinton, whose campaign aims to counter her image as cold and calculating.\n"
     ]
    }
   ],
   "source": [
    "# Create summarization prompt\n",
    "result_1 = results.iloc[0]['chunks']\n",
    "result_2 = results.iloc[1]['chunks']\n",
    "print(f\"Selected chunks for summarization:\\n1. {result_1}\\n2. {result_2}\")\n",
    "\n",
    "prompt = f\"\"\"Summarize the content about the Clinton campaign from the following text:\n",
    "\n",
    "Text 1: {normalize_text(result_1)}\n",
    "\n",
    "Text 2: {normalize_text(result_2)}\n",
    "\n",
    "Summary:\"\"\"\n",
    "\n",
    "# Generate summary\n",
    "summary = await get_completion(kernel, prompt, temperature=0.5)\n",
    "print(f\"Summary (Temperature=0.5):\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "609f8afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are the key points about presidents campaign events?\n",
      "\n",
      "RAG Answer: The key points about presidential campaign events, based on the provided context, include:\n",
      "\n",
      "1. **Authenticity Concerns**: There is a strong emphasis on authenticity in campaign events, especially in states like Iowa where personal interaction with voters is crucial. The use of party insiders instead of typical voters can be seen negatively.\n",
      "\n",
      "2. **Astroturfing**: The practice of setting up staged or faux events for media coverage is common in politics, but it can backfire if perceived as deceptive, as seen with Hillary Clinton's campaign.\n",
      "\n",
      "3. **Staged Events**: Clinton's campaign faced criticism for orchestrating events that were presented as spontaneous interactions with ordinary voters. This included a coffee shop meeting in Iowa where attendees were reportedly recruited by the campaign.\n",
      "\n",
      "4. **Image Management**: Clinton's campaign was focused on managing her image as a relatable and spontaneous candidate, countering perceptions of her as cold and calculating. This involved carefully coordinated appearances and media leaks to shape public perception.\n",
      "\n",
      "5. **Potential Backlash**: While scripting appearances is a common tactic, it can be particularly damaging if it contradicts the candidate's intended image or if voters perceive it as inauthentic.\n",
      "\n",
      "Overall, the context highlights the delicate balance campaigns must maintain between managing a candidate's image and ensuring authenticity in voter interactions.\n"
     ]
    }
   ],
   "source": [
    "# Complete RAG demonstration: Search + Summarize\n",
    "\n",
    "#TODO: Change this test query and see how it affects the results\n",
    "test_query = \"What are the key points about presidents campaign events?\"\n",
    "\n",
    "# Search for relevant documents\n",
    "search_results_df = search_docs(embed_df, test_query, top_n=3)\n",
    "\n",
    "# Create context from search results\n",
    "context = \"\\n\\n\".join(search_results_df['chunks'].tolist())\n",
    "\n",
    "# Generate RAG response using the context\n",
    "rag_prompt = f\"\"\"Based on the following context, answer the question: {test_query}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "final_response = await get_completion(kernel, rag_prompt, temperature=0.2)\n",
    "\n",
    "print(f\"Query: {test_query}\")\n",
    "print(f\"\\nRAG Answer: {final_response}\")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
